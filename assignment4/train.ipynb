{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import time\n",
    "from torch.legacy.nn.Module import Module\n",
    "from torch.legacy.nn.utils import clear\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SpatialCrossMapLRN_temp(Module):\n",
    "    def __init__(self, size, alpha=1e-4, beta=0.75, k=1, gpuDevice=0):\n",
    "        super(SpatialCrossMapLRN_temp, self).__init__()\n",
    "\n",
    "        self.size = size\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        self.scale = None\n",
    "        self.paddedRatio = None\n",
    "        self.accumRatio = None\n",
    "        self.gpuDevice = gpuDevice\n",
    "\n",
    "    def updateOutput(self, input):\n",
    "        assert input.dim() == 4\n",
    "\n",
    "        if self.scale is None:\n",
    "            self.scale = input.new()\n",
    "\n",
    "        if self.output is None:\n",
    "            self.output = input.new()\n",
    "\n",
    "        batchSize = input.size(0)\n",
    "        channels = input.size(1)\n",
    "        inputHeight = input.size(2)\n",
    "        inputWidth = input.size(3)\n",
    "\n",
    "        if input.is_cuda:\n",
    "            self.output = self.output.cuda(self.gpuDevice)\n",
    "            self.scale = self.scale.cuda(self.gpuDevice)\n",
    "\n",
    "        self.output.resize_as_(input)\n",
    "        self.scale.resize_as_(input)\n",
    "\n",
    "        # use output storage as temporary buffer\n",
    "        inputSquare = self.output\n",
    "        torch.pow(input, 2, out=inputSquare)\n",
    "\n",
    "        prePad = int((self.size - 1) / 2 + 1)\n",
    "        prePadCrop = channels if prePad > channels else prePad\n",
    "\n",
    "        scaleFirst = self.scale.select(1, 0)\n",
    "        scaleFirst.zero_()\n",
    "        # compute first feature map normalization\n",
    "        for c in range(prePadCrop):\n",
    "            scaleFirst.add_(inputSquare.select(1, c))\n",
    "\n",
    "        # reuse computations for next feature maps normalization\n",
    "        # by adding the next feature map and removing the previous\n",
    "        for c in range(1, channels):\n",
    "            scalePrevious = self.scale.select(1, c - 1)\n",
    "            scaleCurrent = self.scale.select(1, c)\n",
    "            scaleCurrent.copy_(scalePrevious)\n",
    "            if c < channels - prePad + 1:\n",
    "                squareNext = inputSquare.select(1, c + prePad - 1)\n",
    "                scaleCurrent.add_(1, squareNext)\n",
    "\n",
    "            if c > prePad:\n",
    "                squarePrevious = inputSquare.select(1, c - prePad)\n",
    "                scaleCurrent.add_(-1, squarePrevious)\n",
    "\n",
    "        self.scale.mul_(self.alpha / self.size).add_(self.k)\n",
    "\n",
    "        torch.pow(self.scale, -self.beta, out=self.output)\n",
    "        self.output.mul_(input)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def updateGradInput(self, input, gradOutput):\n",
    "        assert input.dim() == 4\n",
    "\n",
    "        batchSize = input.size(0)\n",
    "        channels = input.size(1)\n",
    "        inputHeight = input.size(2)\n",
    "        inputWidth = input.size(3)\n",
    "\n",
    "        if self.paddedRatio is None:\n",
    "            self.paddedRatio = input.new()\n",
    "        if self.accumRatio is None:\n",
    "            self.accumRatio = input.new()\n",
    "        self.paddedRatio.resize_(channels + self.size - 1, inputHeight,\n",
    "                                 inputWidth)\n",
    "        self.accumRatio.resize_(inputHeight, inputWidth)\n",
    "\n",
    "        cacheRatioValue = 2 * self.alpha * self.beta / self.size\n",
    "        inversePrePad = int(self.size - (self.size - 1) / 2)\n",
    "\n",
    "        self.gradInput.resize_as_(input)\n",
    "        torch.pow(self.scale, -self.beta, out=self.gradInput).mul_(gradOutput)\n",
    "\n",
    "        self.paddedRatio.zero_()\n",
    "        paddedRatioCenter = self.paddedRatio.narrow(0, inversePrePad, channels)\n",
    "        for n in range(batchSize):\n",
    "            torch.mul(gradOutput[n], self.output[n], out=paddedRatioCenter)\n",
    "            paddedRatioCenter.div_(self.scale[n])\n",
    "            torch.sum(\n",
    "                self.paddedRatio.narrow(0, 0, self.size - 1),\n",
    "                0,\n",
    "                out=self.accumRatio)\n",
    "            for c in range(channels):\n",
    "                self.accumRatio.add_(self.paddedRatio[c + self.size - 1])\n",
    "                self.gradInput[n][c].addcmul_(-cacheRatioValue, input[n][c],\n",
    "                                              self.accumRatio)\n",
    "                self.accumRatio.add_(-1, self.paddedRatio[c])\n",
    "\n",
    "        return self.gradInput\n",
    "\n",
    "    def clearState(self):\n",
    "        clear(self, 'scale', 'paddedRatio', 'accumRatio')\n",
    "        return super(SpatialCrossMapLRN_temp, self).clearState()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "\n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "\n",
    "\n",
    "#\n",
    "def Conv2d(in_dim, out_dim, kernel, stride, padding):\n",
    "    l = torch.nn.Conv2d(in_dim, out_dim, kernel, stride=stride, padding=padding)\n",
    "    return l\n",
    "\n",
    "def BatchNorm(dim):\n",
    "    l = torch.nn.BatchNorm2d(dim)\n",
    "    return l\n",
    "\n",
    "def CrossMapLRN(size, alpha, beta, k=1.0, gpuDevice=0):\n",
    "    lrn = SpatialCrossMapLRN_temp(size, alpha, beta, k, gpuDevice=gpuDevice)\n",
    "    n = Lambda( lambda x,lrn=lrn: Variable(lrn.forward(x.data).cuda(gpuDevice)) if x.data.is_cuda else Variable(lrn.forward(x.data)) )\n",
    "    return n\n",
    "\n",
    "def Linear(in_dim, out_dim):\n",
    "    l = torch.nn.Linear(in_dim, out_dim)\n",
    "    return l\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, inputSize, kernelSize, kernelStride, outputSize, reduceSize, pool, useBatchNorm, reduceStride=None, padding=True):\n",
    "        super(Inception, self).__init__()\n",
    "        #\n",
    "        self.seq_list = []\n",
    "        self.outputSize = outputSize\n",
    "\n",
    "        #\n",
    "        # 1x1 conv (reduce) -> 3x3 conv\n",
    "        # 1x1 conv (reduce) -> 5x5 conv\n",
    "        # ...\n",
    "        for i in range(len(kernelSize)):\n",
    "            od = OrderedDict()\n",
    "            # 1x1 conv\n",
    "            od['1_conv'] = Conv2d(inputSize, reduceSize[i], (1, 1), reduceStride[i] if reduceStride is not None else 1, (0,0))\n",
    "            if useBatchNorm:\n",
    "                od['2_bn'] = BatchNorm(reduceSize[i])\n",
    "            od['3_relu'] = nn.ReLU()\n",
    "            # nxn conv\n",
    "            pad = int(numpy.floor(kernelSize[i] / 2)) if padding else 0\n",
    "            od['4_conv'] = Conv2d(reduceSize[i], outputSize[i], kernelSize[i], kernelStride[i], pad)\n",
    "            if useBatchNorm:\n",
    "                od['5_bn'] = BatchNorm(outputSize[i])\n",
    "            od['6_relu'] = nn.ReLU()\n",
    "            #\n",
    "            self.seq_list.append(nn.Sequential(od))\n",
    "\n",
    "        ii = len(kernelSize)\n",
    "        # pool -> 1x1 conv\n",
    "        od = OrderedDict()\n",
    "        od['1_pool'] = pool\n",
    "        if ii < len(reduceSize) and reduceSize[ii] is not None:\n",
    "            i = ii\n",
    "            od['2_conv'] = Conv2d(inputSize, reduceSize[i], (1,1), reduceStride[i] if reduceStride is not None else 1, (0,0))\n",
    "            if useBatchNorm:\n",
    "                od['3_bn'] = BatchNorm(reduceSize[i])\n",
    "            od['4_relu'] = nn.ReLU()\n",
    "        #\n",
    "        self.seq_list.append(nn.Sequential(od))\n",
    "        ii += 1\n",
    "\n",
    "        # reduce: 1x1 conv (channel-wise pooling)\n",
    "        if ii < len(reduceSize) and reduceSize[ii] is not None:\n",
    "            i = ii\n",
    "            od = OrderedDict()\n",
    "            od['1_conv'] = Conv2d(inputSize, reduceSize[i], (1,1), reduceStride[i] if reduceStride is not None else 1, (0,0))\n",
    "            if useBatchNorm:\n",
    "                od['2_bn'] = BatchNorm(reduceSize[i])\n",
    "            od['3_relu'] = nn.ReLU()\n",
    "            self.seq_list.append(nn.Sequential(od))\n",
    "\n",
    "        self.seq_list = nn.ModuleList(self.seq_list)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        ys = []\n",
    "        target_size = None\n",
    "        depth_dim = 0\n",
    "        for seq in self.seq_list:\n",
    "            #print(seq)\n",
    "            #print(self.outputSize)\n",
    "            #print('x_size:', x.size())\n",
    "            y = seq(x)\n",
    "            y_size = y.size()\n",
    "            #print('y_size:', y_size)\n",
    "            ys.append(y)\n",
    "            #\n",
    "            if target_size is None:\n",
    "                target_size = [0] * len(y_size)\n",
    "            #\n",
    "            for i in range(len(target_size)):\n",
    "                target_size[i] = max(target_size[i], y_size[i])\n",
    "            depth_dim += y_size[1]\n",
    "\n",
    "        target_size[1] = depth_dim\n",
    "        #print('target_size:', target_size)\n",
    "\n",
    "        for i in range(len(ys)):\n",
    "            y_size = ys[i].size()\n",
    "            pad_l = int((target_size[3] - y_size[3]) // 2)\n",
    "            pad_t = int((target_size[2] - y_size[2]) // 2)\n",
    "            pad_r = target_size[3] - y_size[3] - pad_l\n",
    "            pad_b = target_size[2] - y_size[2] - pad_t\n",
    "            ys[i] = F.pad(ys[i], (pad_l, pad_r, pad_t, pad_b))\n",
    "\n",
    "        output = torch.cat(ys, 1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class netOpenFace(nn.Module):\n",
    "    def __init__(self, n_class, useCuda=True, gpuDevice=0):\n",
    "        super(netOpenFace, self).__init__()\n",
    "\n",
    "        self.gpuDevice = gpuDevice\n",
    "\n",
    "        self.layer1 = Conv2d(3, 64, (7,7), (2,2), (3,3))\n",
    "        self.layer2 = BatchNorm(64)\n",
    "        self.layer3 = nn.ReLU()\n",
    "        self.layer4 = nn.MaxPool2d((3,3), stride=(2,2), padding=(1,1))\n",
    "        self.layer5 = CrossMapLRN(5, 0.0001, 0.75, gpuDevice=gpuDevice)\n",
    "        self.layer6 = Conv2d(64, 64, (1,1), (1,1), (0,0))\n",
    "        self.layer7 = BatchNorm(64)\n",
    "        self.layer8 = nn.ReLU()\n",
    "        self.layer9 = Conv2d(64, 192, (3,3), (1,1), (1,1))\n",
    "        self.layer10 = BatchNorm(192)\n",
    "        self.layer11 = nn.ReLU()\n",
    "        self.layer12 = CrossMapLRN(5, 0.0001, 0.75, gpuDevice=gpuDevice)\n",
    "        self.layer13 = nn.MaxPool2d((3,3), stride=(2,2), padding=(1,1))\n",
    "        self.layer14 = Inception(192, (3,5), (1,1), (128,32), (96,16,32,64), nn.MaxPool2d((3,3), stride=(2,2), padding=(0,0)), True)\n",
    "        self.layer15 = Inception(256, (3,5), (1,1), (128,64), (96,32,64,64), nn.LPPool2d(2, (3,3), stride=(3,3)), True)\n",
    "        self.layer16 = Inception(320, (3,5), (2,2), (256,64), (128,32,None,None), nn.MaxPool2d((3,3), stride=(2,2), padding=(0,0)), True)\n",
    "        self.layer17 = Inception(640, (3,5), (1,1), (192,64), (96,32,128,256), nn.LPPool2d(2, (3,3), stride=(3,3)), True)\n",
    "        self.layer18 = Inception(640, (3,5), (2,2), (256,128), (160,64,None,None), nn.MaxPool2d((3,3), stride=(2,2), padding=(0,0)), True)\n",
    "        self.layer19 = Inception(1024, (3,), (1,), (384,), (96,96,256), nn.LPPool2d(2, (3,3), stride=(3,3)), True)\n",
    "        self.layer21 = Inception(736, (3,), (1,), (384,), (96,96,256), nn.MaxPool2d((3,3), stride=(2,2), padding=(0,0)), True)\n",
    "        self.layer22 = nn.AvgPool2d((3,3), stride=(1,1), padding=(0,0))\n",
    "        self.layer25 = Linear(736, 128)\n",
    "        self.classifier = Linear(736, n_class)\n",
    "\n",
    "        #\n",
    "        self.resize1 = nn.UpsamplingNearest2d(scale_factor=3)\n",
    "        self.resize2 = nn.AvgPool2d(4)\n",
    "\n",
    "        #\n",
    "        # self.eval()\n",
    "\n",
    "        if useCuda:\n",
    "            self.cuda(gpuDevice)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        if x.data.is_cuda and self.gpuDevice != 0:\n",
    "            x = x.cuda(self.gpuDevice)\n",
    "\n",
    "        #\n",
    "        if x.size()[-1] == 128:\n",
    "            x = self.resize2(self.resize1(x))\n",
    "\n",
    "        x = self.layer8(self.layer7(self.layer6(self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x))))))))\n",
    "        x = self.layer13(self.layer12(self.layer11(self.layer10(self.layer9(x)))))\n",
    "        x = self.layer14(x)\n",
    "        x = self.layer15(x)\n",
    "        x = self.layer16(x)\n",
    "        x = self.layer17(x)\n",
    "        x = self.layer18(x)\n",
    "        x = self.layer19(x)\n",
    "        x = self.layer21(x)\n",
    "        x = self.layer22(x)\n",
    "        x = x.view((-1, 736))\n",
    "        \n",
    "        out = self.classifier(x)\n",
    "        x = self.layer25(x)\n",
    "\n",
    "        x_norm = torch.sqrt(torch.sum(x**2, 1) + 1e-6)\n",
    "        x = torch.div(x, x_norm.view(-1, 1).expand_as(x))\n",
    "\n",
    "        return out, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = netOpenFace(1580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loader(img):\n",
    "    img = cv2.imread(img)\n",
    "    return img.astype('float32')[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_transform(img):\n",
    "    img = img / 255.\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.permute(2, 0, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = ImageFolder('./data/train', img_transform, loader=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_set, 512, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 6.180883, acc: 0.034854, time: 308.26\n",
      "epoch: 1, loss: 4.770147, acc: 0.134029, time: 303.29\n",
      "epoch: 2, loss: 3.698113, acc: 0.274548, time: 301.81\n",
      "epoch: 3, loss: 2.836275, acc: 0.417461, time: 302.19\n",
      "epoch: 4, loss: 2.201561, acc: 0.067560, time: 302.00\n",
      "epoch: 5, loss: 1.739024, acc: 0.126162, time: 301.67\n",
      "epoch: 6, loss: 1.390450, acc: 0.194974, time: 301.11\n",
      "epoch: 7, loss: 1.122365, acc: 0.248788, time: 301.31\n",
      "epoch: 8, loss: 0.904284, acc: 0.291655, time: 301.17\n",
      "epoch: 9, loss: 0.741591, acc: 0.323109, time: 301.32\n",
      "epoch: 10, loss: 0.613038, acc: 0.348979, time: 301.11\n",
      "epoch: 11, loss: 0.507989, acc: 0.370613, time: 301.58\n",
      "epoch: 12, loss: 0.432686, acc: 0.386563, time: 301.07\n",
      "epoch: 13, loss: 0.377603, acc: 0.398036, time: 301.37\n",
      "epoch: 14, loss: 0.327222, acc: 0.410676, time: 301.68\n",
      "epoch: 15, loss: 0.292278, acc: 0.418608, time: 301.53\n",
      "epoch: 16, loss: 0.269492, acc: 0.424497, time: 301.61\n",
      "epoch: 17, loss: 0.250267, acc: 0.429039, time: 301.11\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    running_loss = 0\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    start = time.time()\n",
    "    for data in train_data:\n",
    "        img = Variable(data[0].cuda())\n",
    "        label = Variable(data[1].cuda())\n",
    "        bs = img.size(0)\n",
    "        # forward\n",
    "        output, _ = net(img)\n",
    "        loss = criterion(output, label)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "        total += bs\n",
    "        correct = (output.max(1)[1] == label).sum()\n",
    "        acc += correct.data[0]\n",
    "        \n",
    "    during = time.time() - start\n",
    "    log_str = 'epoch: {}, loss: {:.6f}, acc: {:.6f}, time: {:.2f}'.format(e, running_loss / total, acc / total, during)\n",
    "    print(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'save_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
